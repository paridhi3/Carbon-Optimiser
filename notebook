# CHAINING
EMISSION_FACTORS = {
    "transport": {
        "car_gasoline": 0.21,
        "car_diesel": 0.23,
        "electric_car": 0.05,
        "bus": 0.09,
        "train": 0.04,
        "bike": 0.0,
        "walk": 0.0
    },
    "energy": {
        "electricity_avg": 0.4,
        "electricity_renewable": 0.05,
        "natural_gas": 0.19,
        "heating_oil": 0.27
    },
    "diet": {
        "beef": 5.0,
        "lamb": 4.8,
        "chicken": 1.8,
        "pork": 2.4,
        "fish": 2.0,
        "eggs": 1.6,
        "milk": 1.2,
        "cheese": 3.0,
        "lentils": 0.9,
        "beans": 1.0,
        "tofu": 1.3,
        "vegetables": 0.5
    }
}

from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

extraction_prompt = ChatPromptTemplate.from_template("""
Extract the following details from the user input:

transport: one of {valid_transports}
distance_km: number (total weekly distance in km)
energy: one of {valid_energies}
energy_kwh: number
diet: one of {valid_diets}
meals_per_week: number

Respond ONLY in this JSON format:
{{
  "transport": ...,
  "distance_km": ...,
  "energy": ...,
  "energy_kwh": ...,
  "diet": ...,
  "meals_per_week": ...
}}

User input: {input}
""")

extraction_chain = LLMChain(
    llm=llm,
    prompt=extraction_prompt.partial(
        valid_transports=", ".join(EMISSION_FACTORS["transport"].keys()),
        valid_energies=", ".join(EMISSION_FACTORS["energy"].keys()),
        valid_diets=", ".join(EMISSION_FACTORS["diet"].keys())
    )
)

agent_executor.invoke({
    "input": extraction_chain.run(input="Hi my name is Paridhi. I drove 10km by car today. What is my carbon footprint?"), 
    "chat_history": memory.chat_memory.messages
})

Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]
